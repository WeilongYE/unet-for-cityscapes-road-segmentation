{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WeilongYE/unet-for-cityscapes-road-segmentation/blob/main/unet_for_cityscapes_road_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PDco7dVM9Jo"
      },
      "source": [
        "# UNet for Cityscapes Road Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "- 1. Data Preparation\n",
        "  - 1.1 Download Datasets\n",
        "    - 1.1.1 Setup Kaggle API Key in Colab\n",
        "    - 1.1.2 Download Cityscapes RGB Images\n",
        "    - 1.1.3 Inspect RGB Images\n",
        "    - 1.1.4 Reorgnize RGB Images\n",
        "    - 1.1.5 Download Fine Annotations\n",
        "    - 1.1.6 Inspect Label Images\n",
        "    - 1.1.7 Reorgnize Label Images\n",
        "    - 1.1.8 Check Relative RGB and Label Images\n",
        "  - 1.2 Data Inspection\n",
        "    - 1.2.1 General Info\n",
        "    - 1.2.2 Label Info\n",
        "  - 1.3 Load and Preprocess Datasets\n",
        "    - 1.3.1 Binary Datasets"
      ],
      "metadata": {
        "id": "p2ehkFLm8myk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Preparation"
      ],
      "metadata": {
        "id": "cZcxjmtmnXBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Download Datasets\n",
        "All the datasets are downloaded from Kaggle."
      ],
      "metadata": {
        "id": "oOhQPGgGO2QI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1.1 Setup Kaggle API Key in Colab"
      ],
      "metadata": {
        "id": "5X4mfNCom9K3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Get the Kaggle APIÂ Key. https://www.kaggle.com/docs/api#authentication\n",
        "# - Go to Kaggle and log in.\n",
        "# - Click on your profile picture (top right), then select Settings.\n",
        "# - Scroll down to the API section and click Create New API Token.\n",
        "# - A file named kaggle.json will be downloaded.\n",
        "from google.colab import files\n",
        "files.upload()  # This will prompt you to upload the kaggle.json file\n",
        "\n",
        "# Step 2: Move kaggle key to proper location\n",
        "import os\n",
        "import shutil\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "shutil.move(\"kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "dtFJotKioFCA",
        "outputId": "dd1df6be-47fa-403e-9c68-90eae41f864b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-42b5f8b0-5b7e-4f61-b9c3-f2192fe102cf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-42b5f8b0-5b7e-4f61-b9c3-f2192fe102cf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1.2 Download Cityscapes RGB Images\n",
        "Kaggle datasets link: https://www.kaggle.com/datasets/chrisviviers/cityscapes-leftimg8bit-trainvaltest"
      ],
      "metadata": {
        "id": "vKnW4eq8olwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downlad datasets from Kaggle\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"chrisviviers/cityscapes-leftimg8bit-trainvaltest\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "vzX-ABQrOssd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "downloaded_rgb_dir = \"downloaded_datasets/rgb\"\n",
        "shutil.rmtree(downloaded_rgb_dir, ignore_errors=True)\n",
        "os.makedirs(downloaded_rgb_dir, exist_ok=True)\n",
        "shutil.move(path, downloaded_rgb_dir)"
      ],
      "metadata": {
        "id": "0LLhnvjXp-Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1.3 Inspect RGB Images"
      ],
      "metadata": {
        "id": "nNOkXI3ArrO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def get_all_files(dir_name):\n",
        "  file_paths = []\n",
        "  for root, dirs, files in os.walk(dir_name):\n",
        "    for file in files:\n",
        "      file_paths.append(os.path.join(root, file))\n",
        "  return file_paths\n",
        "\n",
        "all_files = get_all_files(\"downloaded_datasets/rgb/1\")\n",
        "\n",
        "downloaded_train_rgb_files = [file for file in all_files if \"leftImg8bit\" in file and \"train\" in file]\n",
        "downloaded_val_rgb_files = [file for file in all_files if \"leftImg8bit\" in file and \"val\" in file]\n",
        "print(len(downloaded_train_rgb_files))\n",
        "print(len(downloaded_val_rgb_files))\n",
        "\n",
        "train_rgb_img = np.array(Image.open(downloaded_train_rgb_files[0]))\n",
        "val_rgb_img = np.array(Image.open(downloaded_val_rgb_files[0]))\n",
        "print(train_rgb_img.shape)\n",
        "print(val_rgb_img.shape)\n",
        "fig, axis = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axis[0].set_title(\"train\")\n",
        "axis[0].imshow(train_rgb_img)\n",
        "axis[1].set_title(\"val\")\n",
        "axis[1].imshow(val_rgb_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LmcZR6wcrxUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1.4 Reorgnize and Resize RGB Images\n",
        "The struture should be:\n",
        "- cityscapes_data/train/rgb/filename.png\n",
        "- cityscapes_data/val/rgb/filename.png"
      ],
      "metadata": {
        "id": "I0ZdSO8NsQgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_rgb_dir = os.path.join(\"cityscapes_data/train/rgb\")\n",
        "val_rgb_dir = os.path.join(\"cityscapes_data/val/rgb\")\n",
        "shutil.rmtree(train_rgb_dir, ignore_errors=True)\n",
        "shutil.rmtree(val_rgb_dir, ignore_errors=True)\n",
        "os.makedirs(train_rgb_dir, exist_ok=True)\n",
        "os.makedirs(val_rgb_dir, exist_ok=True)\n",
        "\n",
        "save_shape = (256, 256)\n",
        "\n",
        "for file in downloaded_train_rgb_files:\n",
        "  # open, resize and save image\n",
        "  image = Image.open(file).resize(save_shape, Image.NEAREST)\n",
        "  dst_filename = os.path.basename(file.replace(\"_leftImg8bit\", \"\"))\n",
        "  image.save(os.path.join(train_rgb_dir, dst_filename))\n",
        "\n",
        "for file in downloaded_val_rgb_files:\n",
        "  image = Image.open(file).resize(save_shape, Image.NEAREST)\n",
        "  dst_filename = os.path.basename(file.replace(\"_leftImg8bit\", \"\"))\n",
        "  image.save(os.path.join(val_rgb_dir, dst_filename))"
      ],
      "metadata": {
        "id": "i5jLMLrosnJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check re-orgnized rgb files\n",
        "\n",
        "train_rgb_files = os.listdir(train_rgb_dir)\n",
        "val_rgb_files = os.listdir(val_rgb_dir)\n",
        "print(len(train_rgb_files))\n",
        "print(len(val_rgb_files))\n",
        "\n",
        "fig, axis = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axis[0].set_title(\"train\")\n",
        "axis[0].imshow(Image.open(os.path.join(train_rgb_dir, train_rgb_files[0])))\n",
        "axis[1].set_title(\"val\")\n",
        "axis[1].imshow(Image.open(os.path.join(val_rgb_dir, val_rgb_files[0])))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8xmKJp2ytlzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1.5 Download Fine Annotations\n",
        "Kaggle datasets link: https://www.kaggle.com/datasets/devmaxime/cityscapes-fine-annotations"
      ],
      "metadata": {
        "id": "izYyiX6DmiBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download datasets\n",
        "path = kagglehub.dataset_download(\"devmaxime/cityscapes-fine-annotations\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "5V0VxteklAdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "downloaded_label_dir = \"downloaded_datasets/label\"\n",
        "shutil.rmtree(downloaded_label_dir, ignore_errors=True)\n",
        "os.makedirs(downloaded_label_dir, exist_ok=True)\n",
        "shutil.move(path, downloaded_label_dir)"
      ],
      "metadata": {
        "id": "YapRpzKwz41a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1.6 Inspect Label Images"
      ],
      "metadata": {
        "id": "2WKUZM5I0b2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_files = get_all_files(\"downloaded_datasets/label/1\")\n",
        "downloaded_train_labelIds_files = [file for file in all_files if \"gtFine_labelIds\" in file and \"train\" in file]\n",
        "downloaded_val_labelIds_files = [file for file in all_files if \"gtFine_labelIds\" in file and \"val\" in file]\n",
        "print(len(downloaded_train_labelIds_files))\n",
        "print(len(downloaded_val_labelIds_files))\n",
        "\n",
        "train_labelIds_img = np.array(Image.open(downloaded_train_labelIds_files[0]))\n",
        "val_labelIds_img = np.array(Image.open(downloaded_val_labelIds_files[0]))\n",
        "print(train_labelIds_img.shape)\n",
        "print(val_labelIds_img.shape)\n",
        "\n",
        "fig, axis = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axis[0].set_title(\"train label\")\n",
        "axis[0].imshow(train_labelIds_img)\n",
        "axis[1].set_title(\"val label\")\n",
        "axis[1].imshow(val_labelIds_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pfmD_cE70f5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1.7 Reorgnize and Resize Label Images\n",
        "The structure should be like:\n",
        "- cityscapes_data/train/label_ids/filename.png\n",
        "- cityscapes_data/val/label_ids/filename.png"
      ],
      "metadata": {
        "id": "FMxe0uFH1Pvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folders\n",
        "train_label_dir = os.path.join(\"cityscapes_data/train/label\")\n",
        "val_label_dir = os.path.join(\"cityscapes_data/val/label\")\n",
        "shutil.rmtree(train_label_dir, ignore_errors=True)\n",
        "shutil.rmtree(val_label_dir, ignore_errors=True)\n",
        "os.makedirs(train_label_dir, exist_ok=True)\n",
        "os.makedirs(val_label_dir, exist_ok=True)\n",
        "\n",
        "for file in downloaded_train_labelIds_files:\n",
        "  # Open, resize and save label image\n",
        "  image = Image.open(file).resize(save_shape, Image.NEAREST)\n",
        "  dst_filename = os.path.basename(file.replace(\"_gtFine_labelIds\", \"\"))\n",
        "  image.save(os.path.join(train_label_dir, dst_filename))\n",
        "\n",
        "for file in downloaded_val_labelIds_files:\n",
        "  image = Image.open(file).resize(save_shape, Image.NEAREST)\n",
        "  dst_filename = os.path.basename(file.replace(\"_gtFine_labelIds\", \"\"))\n",
        "  image.save(os.path.join(val_label_dir, dst_filename))"
      ],
      "metadata": {
        "id": "d_XcYLyf1go8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check re-orgnized label images\n",
        "train_label_files = os.listdir(train_label_dir)\n",
        "val_label_files = os.listdir(val_label_dir)\n",
        "print(len(train_label_files))\n",
        "print(len(val_label_files))\n",
        "\n",
        "fig, axis = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axis[0].set_title(\"train\")\n",
        "axis[0].imshow(Image.open(os.path.join(train_label_dir, train_label_files[0])))\n",
        "axis[1].set_title(\"val\")\n",
        "axis[1].imshow(Image.open(os.path.join(val_label_dir, val_label_files[0])))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fzl88Dw02qGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1.8 Check Relative RGB and Label Images"
      ],
      "metadata": {
        "id": "n9vYJubM3E8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all filenamess in train/rgb are also in train/label\n",
        "for file in train_rgb_files:\n",
        "  if file not in train_label_files:\n",
        "    print(file)\n",
        "\n",
        "common_filename = train_rgb_files[0]\n",
        "fig, axis = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axis[0].set_title(\"rgb\")\n",
        "axis[0].imshow(Image.open(os.path.join(train_rgb_dir, common_filename)))\n",
        "axis[1].set_title(\"label\")\n",
        "axis[1].imshow(Image.open(os.path.join(train_label_dir, common_filename)))\n",
        "plt.show()\n",
        "\n",
        "# Check if all filenamess in val/rgb are also in val/label\n",
        "for file in val_rgb_files:\n",
        "  if file not in val_label_files:\n",
        "    print(file)\n",
        "\n",
        "common_filename = val_rgb_files[0]\n",
        "fig, axis = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axis[0].set_title(\"rgb\")\n",
        "axis[0].imshow(Image.open(os.path.join(val_rgb_dir, common_filename)))\n",
        "axis[1].set_title(\"label\")\n",
        "axis[1].imshow(Image.open(os.path.join(val_label_dir, common_filename)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zBCZNcW63QD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Data Inspection"
      ],
      "metadata": {
        "id": "I6PlWUsK4OKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1 General Info"
      ],
      "metadata": {
        "id": "DrX5Fy6WsJDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of train samples: {len(train_rgb_files)}\")\n",
        "print(f\"Number of val samples: {len(val_rgb_files)}\")\n",
        "print(f\"Shape of RGB images: {np.array(Image.open(os.path.join(train_rgb_dir,train_rgb_files[0]))).shape}\")\n",
        "print(f\"Shape of label images: {np.array(Image.open(os.path.join(train_label_dir,train_label_files[0]))).shape}\")\n"
      ],
      "metadata": {
        "id": "W60Z7O6U0aJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.2 Label Info\n",
        "Below code cell is a partial copy of https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/helpers/labels.py\n"
      ],
      "metadata": {
        "id": "1Z4uYNk8sRoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "# Definitions\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "# a label and all meta information\n",
        "Label = namedtuple( 'Label' , [\n",
        "\n",
        "    'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n",
        "                    # We use them to uniquely name a class\n",
        "\n",
        "    'id'          , # An integer ID that is associated with this label.\n",
        "                    # The IDs are used to represent the label in ground truth images\n",
        "                    # An ID of -1 means that this label does not have an ID and thus\n",
        "                    # is ignored when creating ground truth images (e.g. license plate).\n",
        "                    # Do not modify these IDs, since exactly these IDs are expected by the\n",
        "                    # evaluation server.\n",
        "\n",
        "    'trainId'     , # Feel free to modify these IDs as suitable for your method. Then create\n",
        "                    # ground truth images with train IDs, using the tools provided in the\n",
        "                    # 'preparation' folder. However, make sure to validate or submit results\n",
        "                    # to our evaluation server using the regular IDs above!\n",
        "                    # For trainIds, multiple labels might have the same ID. Then, these labels\n",
        "                    # are mapped to the same class in the ground truth images. For the inverse\n",
        "                    # mapping, we use the label that is defined first in the list below.\n",
        "                    # For example, mapping all void-type classes to the same ID in training,\n",
        "                    # might make sense for some approaches.\n",
        "                    # Max value is 255!\n",
        "\n",
        "    'category'    , # The name of the category that this label belongs to\n",
        "\n",
        "    'categoryId'  , # The ID of this category. Used to create ground truth images\n",
        "                    # on category level.\n",
        "\n",
        "    'hasInstances', # Whether this label distinguishes between single instances or not\n",
        "\n",
        "    'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n",
        "                    # during evaluations or not\n",
        "\n",
        "    'color'       , # The color of this label\n",
        "    ] )\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "# A list of all labels\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "# Please adapt the train IDs as appropriate for your approach.\n",
        "# Note that you might want to ignore labels with ID 255 during training.\n",
        "# Further note that the current train IDs are only a suggestion. You can use whatever you like.\n",
        "# Make sure to provide your results using the original IDs and not the training IDs.\n",
        "# Note that many IDs are ignored in evaluation and thus you never need to predict these!\n",
        "\n",
        "labels = [\n",
        "    #       name                     id    trainId   category            catId     hasInstances   ignoreInEval   color\n",
        "    Label(  'unlabeled'            ,  0 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
        "    Label(  'ego vehicle'          ,  1 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
        "    Label(  'rectification border' ,  2 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
        "    Label(  'out of roi'           ,  3 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
        "    Label(  'static'               ,  4 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
        "    Label(  'dynamic'              ,  5 ,      255 , 'void'            , 0       , False        , True         , (111, 74,  0) ),\n",
        "    Label(  'ground'               ,  6 ,      255 , 'void'            , 0       , False        , True         , ( 81,  0, 81) ),\n",
        "    Label(  'road'                 ,  7 ,        0 , 'flat'            , 1       , False        , False        , (128, 64,128) ),\n",
        "    Label(  'sidewalk'             ,  8 ,        1 , 'flat'            , 1       , False        , False        , (244, 35,232) ),\n",
        "    Label(  'parking'              ,  9 ,      255 , 'flat'            , 1       , False        , True         , (250,170,160) ),\n",
        "    Label(  'rail track'           , 10 ,      255 , 'flat'            , 1       , False        , True         , (230,150,140) ),\n",
        "    Label(  'building'             , 11 ,        2 , 'construction'    , 2       , False        , False        , ( 70, 70, 70) ),\n",
        "    Label(  'wall'                 , 12 ,        3 , 'construction'    , 2       , False        , False        , (102,102,156) ),\n",
        "    Label(  'fence'                , 13 ,        4 , 'construction'    , 2       , False        , False        , (190,153,153) ),\n",
        "    Label(  'guard rail'           , 14 ,      255 , 'construction'    , 2       , False        , True         , (180,165,180) ),\n",
        "    Label(  'bridge'               , 15 ,      255 , 'construction'    , 2       , False        , True         , (150,100,100) ),\n",
        "    Label(  'tunnel'               , 16 ,      255 , 'construction'    , 2       , False        , True         , (150,120, 90) ),\n",
        "    Label(  'pole'                 , 17 ,        5 , 'object'          , 3       , False        , False        , (153,153,153) ),\n",
        "    Label(  'polegroup'            , 18 ,      255 , 'object'          , 3       , False        , True         , (153,153,153) ),\n",
        "    Label(  'traffic light'        , 19 ,        6 , 'object'          , 3       , False        , False        , (250,170, 30) ),\n",
        "    Label(  'traffic sign'         , 20 ,        7 , 'object'          , 3       , False        , False        , (220,220,  0) ),\n",
        "    Label(  'vegetation'           , 21 ,        8 , 'nature'          , 4       , False        , False        , (107,142, 35) ),\n",
        "    Label(  'terrain'              , 22 ,        9 , 'nature'          , 4       , False        , False        , (152,251,152) ),\n",
        "    Label(  'sky'                  , 23 ,       10 , 'sky'             , 5       , False        , False        , ( 70,130,180) ),\n",
        "    Label(  'person'               , 24 ,       11 , 'human'           , 6       , True         , False        , (220, 20, 60) ),\n",
        "    Label(  'rider'                , 25 ,       12 , 'human'           , 6       , True         , False        , (255,  0,  0) ),\n",
        "    Label(  'car'                  , 26 ,       13 , 'vehicle'         , 7       , True         , False        , (  0,  0,142) ),\n",
        "    Label(  'truck'                , 27 ,       14 , 'vehicle'         , 7       , True         , False        , (  0,  0, 70) ),\n",
        "    Label(  'bus'                  , 28 ,       15 , 'vehicle'         , 7       , True         , False        , (  0, 60,100) ),\n",
        "    Label(  'caravan'              , 29 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0, 90) ),\n",
        "    Label(  'trailer'              , 30 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0,110) ),\n",
        "    Label(  'train'                , 31 ,       16 , 'vehicle'         , 7       , True         , False        , (  0, 80,100) ),\n",
        "    Label(  'motorcycle'           , 32 ,       17 , 'vehicle'         , 7       , True         , False        , (  0,  0,230) ),\n",
        "    Label(  'bicycle'              , 33 ,       18 , 'vehicle'         , 7       , True         , False        , (119, 11, 32) ),\n",
        "    Label(  'license plate'        , -1 ,       -1 , 'vehicle'         , 7       , False        , True         , (  0,  0,142) ),\n",
        "]"
      ],
      "metadata": {
        "id": "MRrdjKgMkAvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_to_id = {label.name: label.id for label in labels}\n",
        "road_id = name_to_id[\"road\"]\n",
        "print(f\"The id of road is: {road_id}\")"
      ],
      "metadata": {
        "id": "ikBrAA6r6M6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect one label image\n",
        "one_label_img = np.array(Image.open(os.path.join(train_label_dir, train_label_files[0])))\n",
        "# reshape label image to three dimention\n",
        "one_label_img = np.reshape(one_label_img, (one_label_img.shape[0], one_label_img.shape[1], 1))\n",
        "print(one_label_img.shape)\n",
        "print(np.unique(one_label_img))\n",
        "\n",
        "road_mask = np.all(one_label_img == road_id, axis=-1).astype(np.uint8)\n",
        "fig, axis = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axis[0].imshow(one_label_img)\n",
        "axis[0].set_title(\"color label\")\n",
        "axis[1].imshow(road_mask)\n",
        "axis[1].set_title(\"road mask\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3GALNC5G6xBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Load and Preprocess Datasets\n",
        "In this experiment, three strategies will be used:\n",
        "- Binary semantic segmentation: road class vs non-road class\n",
        "- Multi-class semantic segmentation based on *id*\n",
        "\n",
        "Constraints:\n",
        "- Three dataset should have same resolution"
      ],
      "metadata": {
        "id": "xIkmqGK872KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128, 128, 3)"
      ],
      "metadata": {
        "id": "LbYLZTriQwSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "class DataLoader:\n",
        "  @staticmethod\n",
        "  def preprocess_rgb(image: Image, input_shape) -> np.ndarray:\n",
        "    # resize to input shape\n",
        "    image = image.resize(input_shape[:2], Image.NEAREST)\n",
        "    # normalize\n",
        "    image = np.array(image) / 255.0\n",
        "    return image\n",
        "\n",
        "  @staticmethod\n",
        "  def preprocess_label(label: Image, input_shape, road_id, num_of_classes, one_hot=False) -> np.ndarray:\n",
        "    # resize to input shape\n",
        "    label = label.resize(input_shape[:2], Image.NEAREST)\n",
        "    # convert multi-class label to road binary mask\n",
        "    label = np.array(label)\n",
        "    label = np.reshape(label, (label.shape[0], label.shape[1], 1))\n",
        "    label = np.all(label == road_id, axis=-1).astype(np.uint8)\n",
        "\n",
        "    if one_hot:  # For using categorical cross entropy instead of sparse categorical cross entropy\n",
        "      label = keras.utils.to_categorical(label, num_of_classes)\n",
        "\n",
        "    return label\n",
        "\n",
        "  def __init__(self, train_rgb_dir, train_label_dir, val_rgb_dir, val_label_dir, input_shape, road_id, num_of_classes):\n",
        "    self.train_rgb_dir = train_rgb_dir\n",
        "    self.train_label_dir = train_label_dir\n",
        "    self.val_rgb_dir = val_rgb_dir\n",
        "    self.val_label_dir = val_label_dir\n",
        "    self.input_shape = input_shape\n",
        "    self.road_id = road_id\n",
        "    self.num_of_classes = num_of_classes\n",
        "\n",
        "  def generate_binary_datasets(self):\n",
        "    train_rgb_files = os.listdir(self.train_rgb_dir)\n",
        "    train_label_files = os.listdir(self.train_label_dir)\n",
        "    val_rgb_files = os.listdir(self.val_rgb_dir)\n",
        "    val_label_files = os.listdir(self.val_label_dir)\n",
        "\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "    X_val = []\n",
        "    Y_val = []\n",
        "\n",
        "    for file in train_rgb_files:\n",
        "      # Load and preprocess image\n",
        "      image_train = Image.open(os.path.join(self.train_rgb_dir, file))\n",
        "      image_train = DataLoader.preprocess_rgb(image_train, self.input_shape)\n",
        "      # Load and preprocess label\n",
        "      label_train = Image.open(os.path.join(self.train_label_dir, file))\n",
        "      label_train = DataLoader.preprocess_label(label_train, self.input_shape, self.road_id, self.num_of_classes)\n",
        "      # Add to dataset\n",
        "      X_train.append(image_train)\n",
        "      Y_train.append(label_train)\n",
        "\n",
        "    for file in val_rgb_files:\n",
        "      # Load and preprocess image\n",
        "      image_train = Image.open(os.path.join(self.val_rgb_dir, file))\n",
        "      image_train = DataLoader.preprocess_rgb(image_train, self.input_shape)\n",
        "      # Load and preprocess label\n",
        "      label_train = Image.open(os.path.join(self.val_label_dir, file))\n",
        "      label_train = DataLoader.preprocess_label(label_train, self.input_shape, self.road_id, self.num_of_classes)\n",
        "      # Add to dataset\n",
        "      X_val.append(image_train)\n",
        "      Y_val.append(label_train)\n",
        "\n",
        "    return np.array(X_train), np.array(Y_train), np.array(X_val), np.array(Y_val)"
      ],
      "metadata": {
        "id": "GrOrczb-7c6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test preprocess_rgb\n",
        "test_image = Image.open(os.path.join(train_rgb_dir, train_rgb_files[0]))\n",
        "test_image = DataLoader.preprocess_rgb(test_image, input_shape)\n",
        "print(test_image.shape)\n",
        "\n",
        "# Test preprocess_label\n",
        "test_label = Image.open(os.path.join(train_label_dir, train_label_files[0]))\n",
        "test_label = DataLoader.preprocess_label(test_label, input_shape, road_id, 2, False)\n",
        "print(test_label.shape)\n",
        "print(np.unique(test_label))\n",
        "\n",
        "fig, axis = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axis[0].imshow(test_image)\n",
        "axis[0].set_title(\"rgb\")\n",
        "axis[1].imshow(test_label)\n",
        "axis[1].set_title(\"road mask\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y6Bm1rIET_k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_classes = 2\n",
        "binary_data_loader = DataLoader(train_rgb_dir, train_label_dir, val_rgb_dir, val_label_dir, input_shape, road_id, num_of_classes)\n",
        "X_train, Y_train, X_val, Y_val = binary_data_loader.generate_binary_datasets()"
      ],
      "metadata": {
        "id": "46dJjaicQG-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check loaded binary datasets\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(Y_val.shape)"
      ],
      "metadata": {
        "id": "lqd53TrdYjEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Build UNet Model"
      ],
      "metadata": {
        "id": "jLMAtizUXgG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3J6j7KbI4eTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 UNet Architecture\n",
        "TODO: add details of applied UNet architecture\n"
      ],
      "metadata": {
        "id": "LcOStXieX6Wu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Implementation"
      ],
      "metadata": {
        "id": "BZXJW4-qYkWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import logProcesses\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "class UNet:\n",
        "  def __init__(self, input_shape, num_of_filters, num_of_classes):\n",
        "    self.input_shape = input_shape\n",
        "    self.num_of_filters = num_of_filters\n",
        "    self.num_of_classes = num_of_classes\n",
        "    self.model = None\n",
        "\n",
        "  def build(self):\n",
        "    def double_conv(x, num_of_filters, dropout_prob):\n",
        "      x = tfl.Conv2D(num_of_filters, 3, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
        "      x = tfl.Conv2D(num_of_filters, 3, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
        "      if dropout_prob > 0:\n",
        "        x = tfl.Dropout(dropout_prob)(x)\n",
        "      return x\n",
        "\n",
        "    def down(x):\n",
        "      return tfl.MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "    def up(expansive_input, contractive_input, num_of_filters):\n",
        "      x = tfl.Conv2DTranspose(num_of_filters, 3, strides=(2,2), padding=\"same\")(expansive_input)\n",
        "      return tfl.concatenate([x, contractive_input], axis=3)\n",
        "\n",
        "    # Encoder\n",
        "    inputs = tfl.Input(input_shape)\n",
        "    encoder_conv_1 = double_conv(inputs, self.num_of_filters, 0)\n",
        "    encoder_down_1 = down(encoder_conv_1)\n",
        "    encoder_conv_2 = double_conv(encoder_down_1, self.num_of_filters * 2, 0)\n",
        "    encoder_down_2 = down(encoder_conv_2)\n",
        "    encoder_conv_3 = double_conv(encoder_down_2, self.num_of_filters * 4, 0)\n",
        "    encoder_down_3 = down(encoder_conv_3)\n",
        "    encoder_conv_4 = double_conv(encoder_down_3, self.num_of_filters * 8, 0.3)\n",
        "    encoder_down_4 = down(encoder_conv_4)\n",
        "    encoder_conv_5 = double_conv(encoder_down_4, self.num_of_filters * 16, 0.3)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_up_1 = up(encoder_conv_5, encoder_conv_4, self.num_of_filters * 8)\n",
        "    decoder_conv_1 = double_conv(decoder_up_1, self.num_of_filters * 8, 0)\n",
        "    decoder_up_2 = up(decoder_conv_1, encoder_conv_3, self.num_of_filters * 4)\n",
        "    decoder_conv_2 = double_conv(decoder_up_2, self.num_of_filters * 4, 0)\n",
        "    decoder_up_3 = up(decoder_conv_2, encoder_conv_2, self.num_of_filters * 2)\n",
        "    decoder_conv_3 = double_conv(decoder_up_3, self.num_of_filters * 2, 0)\n",
        "    decoder_up_4 = up(decoder_conv_3, encoder_conv_1, self.num_of_filters)\n",
        "    decoder_conv_4 = double_conv(decoder_up_4, self.num_of_filters, 0)\n",
        "    outputs = tfl.Conv2D(self.num_of_classes, kernel_size=(1,1), padding=\"same\", activation=\"softmax\")(decoder_conv_4)\n",
        "\n",
        "    self.model = tf.keras.Model(inputs, outputs)\n",
        "    return self.model\n",
        "\n",
        "  def train(self, x, y, x_test, y_test, configs, save_dir):\n",
        "    if self.model is None:\n",
        "      self.build()\n",
        "\n",
        "    class EpochCallback(tf.keras.callbacks.Callback):\n",
        "      def __init__(self, x_test, y_test, save_dir, input_shape, iou_list, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "        self.input_shape = input_shape\n",
        "        self.iou_list = iou_list\n",
        "        self.log_dir = os.path.join(save_dir, \"logs\")\n",
        "        os.makedirs(self.log_dir, exist_ok=True)\n",
        "\n",
        "      def on_epoch_end(self, epoch, logs=None):\n",
        "        self.vis_sample(epoch)\n",
        "        self.compute_road_mean_iou()\n",
        "\n",
        "      def compute_road_mean_iou(self):\n",
        "        mean_iou = 0.0\n",
        "        y_pred = self.model.predict(self.x_test) # (500,128,128,2)\n",
        "        y_pred = tf.math.argmax(y_pred, axis=-1) # (500,128,128)\n",
        "        # compute mean IOU\n",
        "        for i in range(self.y_test.shape[0]):\n",
        "          intersection = np.logical_and(self.y_test[i], y_pred[i])\n",
        "          union = np.logical_or(self.y_test[i], y_pred[i])\n",
        "          mean_iou += np.count_nonzero(intersection) / np.count_nonzero(union)\n",
        "\n",
        "        mean_iou /= self.y_test.shape[0]\n",
        "        print(f\" - mean_iou: {mean_iou}\")\n",
        "        self.iou_list.append(mean_iou)\n",
        "\n",
        "      def vis_sample(self, epoch):\n",
        "        origin_img = x_test[0,:,:,:]\n",
        "        img = np.reshape(origin_img, (1,) + self.input_shape) # (1,128,128,3)\n",
        "        mask = y_test[0,:,:] # (128,128)\n",
        "        y_pred = self.model.predict(img) # (1,128,128,2)\n",
        "        y_pred = tf.math.argmax(y_pred, axis=-1) # (1,128,128)\n",
        "        y_pred = np.array(y_pred)\n",
        "        y_pred = np.reshape(y_pred, (input_shape[0], input_shape[1] ,1))\n",
        "        fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize=(15, 5))\n",
        "        axes[0].imshow(origin_img)\n",
        "        axes[0].set_title(\"Input Image\")\n",
        "        axes[1].imshow(mask)\n",
        "        axes[1].set_title(\"GT Mask\")\n",
        "        axes[2].imshow(y_pred)\n",
        "        axes[2].set_title(\"Predicted Mask\")\n",
        "        plt.tight_layout()\n",
        "        #plt.show()\n",
        "        plt.savefig(os.path.join(self.log_dir, f'epoch_{epoch}.png'))\n",
        "\n",
        "    self.model.compile(optimizer=\"adam\",\n",
        "                       loss=tf.keras.losses.SparseCategoricalCrossentropy(), # The output is integer-encoded instead of one-hot encoded\n",
        "                       #loss=\"categorical_crossentropy\", # one-hot encoding is required\n",
        "                       metrics=[\"accuracy\"])\n",
        "    iou_list = []\n",
        "    epoch_callback = EpochCallback(x_test=x_test, y_test=y_test, input_shape=self.input_shape, save_dir=save_dir, iou_list=iou_list)\n",
        "    history = self.model.fit(x=x, y=y, validation_split=0.2, epochs=configs[\"epochs\"], batch_size=configs[\"batch_size\"], callbacks=[epoch_callback])\n",
        "\n",
        "    # save checkpoint\n",
        "    checkpoint_path = os.path.join(save_dir, \"model_checkpoint.keras\")\n",
        "    self.model.save(checkpoint_path)\n",
        "    # save history\n",
        "    history_path = os.path.join(save_dir, \"history.json\")\n",
        "    with open(history_path, \"w\") as f:\n",
        "      json.dump(history.history, f)\n",
        "    # save configs\n",
        "    configs_path = os.path.join(save_dir, \"configs.json\")\n",
        "    with open(configs_path, \"w\") as f:\n",
        "      json.dump(configs, f)\n",
        "    # save mean iou result\n",
        "    iou_path = os.path.join(save_dir, \"mean_iou.json\")\n",
        "    with open(iou_path, \"w\") as f:\n",
        "      json.dump(iou_list, f)\n"
      ],
      "metadata": {
        "id": "xtbpluTiYntB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check model architecture\n",
        "num_of_filters = 64\n",
        "unet = UNet(input_shape, num_of_filters, num_of_classes)\n",
        "#unet.build().summary()"
      ],
      "metadata": {
        "id": "D1qg3VjukGKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Train Models"
      ],
      "metadata": {
        "id": "yZGNjZt7-3Zb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Train Binary Model"
      ],
      "metadata": {
        "id": "6JFmuNA7sAYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Model\n",
        "num_of_filters = 64\n",
        "input_shape = (128, 128, 3)\n",
        "model = UNet(input_shape, num_of_filters, num_of_classes).build()\n",
        "\n",
        "# Train\n",
        "configs = {\"epochs\": 10, \"batch_size\": 32}\n",
        "save_dir = os.path.join(\"results\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "#unet.train(x=X_train[:100], y=Y_train[:100], x_test=X_val[:10], y_test=Y_val[:10], configs=configs, save_dir=save_dir)\n",
        "unet.train(x=X_train, y=Y_train, x_test=X_val, y_test=Y_val, configs=configs, save_dir=save_dir)\n"
      ],
      "metadata": {
        "id": "nsIZQnTDjlR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "- (256,256) vs (128, 128)\n",
        "- binary class vs multi-class\n",
        "- categorical_crossentropy vs SparseCategoricalCrossentropy"
      ],
      "metadata": {
        "id": "P2MRka_m-D5q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NpCYahJ2-WOG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}